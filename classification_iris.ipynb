{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author - Priti Gupta\n",
    "# Submitted - 1st August 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model -  RandomForestClassifier()\n",
      "y_pred:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "y_test:\n",
      "[1 0 2 1 1 0 1 2 1 1 2 0 0 0 0 1 2 1 1 2 0 2 0 2 2 2 2 2 0 0]\n",
      "Accuracy: 1.0\n",
      "--------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Function to parse JSON and create pipelines\n",
    "def parse_json_and_create_pipeline(json_data):\n",
    "    data = json_data\n",
    "\n",
    "    \n",
    "    # Feature Reduction Pipeline\n",
    "    feature_reduction_pipeline = PCA(n_components=int(data['design_state_data']['feature_reduction']['num_of_features_to_keep']))\n",
    "\n",
    "\n",
    "    pipelines = []\n",
    "    algorithms = data['design_state_data']['algorithms']\n",
    "    for algo_name, algo_data in algorithms.items():\n",
    "        if algo_data['is_selected']:\n",
    "            # Model Training Pipeline\n",
    "            if algo_name == 'RandomForestClassifier':\n",
    "                model = RandomForestClassifier()\n",
    "            elif algo_name == 'GradientBoostedTrees':\n",
    "                model = GradientBoostingClassifier()\n",
    "            elif algo_name == 'LogisticRegression':\n",
    "                model = LogisticRegression()\n",
    "            elif algo_name == 'XGBoost':\n",
    "                model = XGBClassifier()\n",
    "            elif algo_name == 'DecisionTreeClassifier':\n",
    "                model = DecisionTreeClassifier()\n",
    "            elif algo_name == 'SVM':\n",
    "                model = SVC()\n",
    "            elif algo_name == 'KNN':\n",
    "                model = KNeighborsClassifier()\n",
    "            elif algo_name == 'ExtraRandomTrees':\n",
    "                model = ExtraTreesClassifier()\n",
    "            elif algo_name == 'NeuralNetwork':\n",
    "                model = MLPClassifier()\n",
    "\n",
    "            pipeline = Pipeline([\n",
    "                ('feature_reduction', feature_reduction_pipeline),\n",
    "                ('model', model)\n",
    "            ])\n",
    "        \n",
    "            pipelines.append(pipeline)\n",
    "    return pipelines\n",
    "\n",
    "\n",
    "# Function to check model accuracy using cross-validation\n",
    "def check_model_accuracy(pipeline, X, y):\n",
    "    y_pred = pipeline.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    print('y_pred:')\n",
    "    print(y_pred)\n",
    "    print('y_test:')\n",
    "    print(y)\n",
    "    return accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load JSON data from file\n",
    "    with open(\"algoparmas_from_ui.json\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset_filename = json_data[\"design_state_data\"][\"session_info\"][\"dataset\"]\n",
    "    dataset = pd.read_csv(dataset_filename)\n",
    "\n",
    "    # Split features and target variable\n",
    "    X = dataset.drop(columns=[\"species\"]).values\n",
    "    y = dataset[\"species\"].values\n",
    "\n",
    "\n",
    "    # Feature Handling Pipeline\n",
    "    numerical_features = [feat_name for feat_name, feat_data in json_data['design_state_data']['feature_handling'].items() if feat_data['feature_variable_type'] == 'numerical']\n",
    "    numerical_features_to_scale = [feat_name for feat_name, feat_data in json_data['design_state_data']['feature_handling'].items() if feat_data['feature_variable_type'] == 'numerical' and feat_data['feature_details']['rescaling'] == 'Rescaling']\n",
    "    text_features = [feat_name for feat_name, feat_data in json_data['design_state_data']['feature_handling'].items() if feat_data['feature_variable_type'] == 'text']\n",
    "\n",
    "    target_var = 'species'\n",
    "    if target_var in text_features:\n",
    "        #Label encode the target variable y\n",
    "        label_encoder = LabelEncoder()\n",
    "        y = label_encoder.fit_transform(y)\n",
    "    \n",
    "    if numerical_features_to_scale in dataset.columns.to_list():\n",
    "        sc = StandardScaler()\n",
    "        sc.fit_transform(X[numerical_features_to_scale])\n",
    "\n",
    "   # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    # Create pipelines based on JSON data\n",
    "    pipelines = parse_json_and_create_pipeline(json_data)\n",
    "   \n",
    "    # Fit each pipeline using GridSearchCV (hyperparameter tuning) and check intermediate results\n",
    "for idx, pipeline in enumerate(pipelines, start=1):\n",
    "    print(f\"Model -  {pipeline['model']}\")\n",
    "\n",
    "    # Grid Search CV\n",
    "    param_grid = {\n",
    "        'model__n_estimators': [50, 100, 150],\n",
    "        'model__max_depth': [None, 5, 10],\n",
    "        'model__min_samples_split': [2, 5],\n",
    "    }\n",
    "    hyperparameters = json_data[\"design_state_data\"][\"hyperparameters\"]\n",
    "    parallelism = hyperparameters.get(\"parallelism\", None)\n",
    "    num_of_folds = hyperparameters.get(\"num_of_folds\", None)\n",
    "\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=num_of_folds,scoring = 'accuracy',n_jobs=parallelism)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    accuracy = check_model_accuracy(grid_search, X_test, y_test)\n",
    "    #print(\"Best Parameters obtained from grid_search are:\")\n",
    "    #print(grid_search.best_params_)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(\"--------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
